{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxqVz6ou9wwese1HljucTc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yousrabougara/WalmartSalesForecasting/blob/main/Autogluon_Tabular_LagFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0KgIM2TeMy1",
        "outputId": "c7aaf872-2049-4326-bb8f-53d282ba445b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogluon.tabular[all] in /usr/local/lib/python3.11/dist-packages (1.2)\n",
            "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.13.1)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.5.3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.5.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (3.4.2)\n",
            "Requirement already satisfied: autogluon.core==1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.2)\n",
            "Requirement already satisfied: autogluon.features==1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.2)\n",
            "Requirement already satisfied: catboost<1.3,>=1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.2.7)\n",
            "Requirement already satisfied: spacy<3.8 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (3.7.5)\n",
            "Requirement already satisfied: lightgbm<4.6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (4.5.0)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (0.8.0)\n",
            "Requirement already satisfied: xgboost<2.2,>=1.6 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.1.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.7.18)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (0.28.1)\n",
            "Requirement already satisfied: torch<2.6,>=2.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (3.10.0)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (1.36.19)\n",
            "Requirement already satisfied: autogluon.common==1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (1.2)\n",
            "Requirement already satisfied: ray<2.40,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.39.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (17.0.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.2.7)\n",
            "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.tabular[all]) (5.9.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (1.17.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.7.29)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.20.1+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (6.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: safetensors[torch] in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.37.0,>=1.36.19 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all]) (1.36.19)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all]) (0.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.10.9.7)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (3.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (8.1.8)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.21.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.25.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.5.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.11.12)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.11.4)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.21.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (7.1.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (20.29.2)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.70.0)\n",
            "Requirement already satisfied: memray in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.15.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.6.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]) (0.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8->autogluon.tabular[all]) (3.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.4.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (25.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.18.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.17.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.3.6)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.22.3)\n",
            "Requirement already satisfied: textual>=0.41.0 in /usr/local/lib/python3.11/dist-packages (from memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.19.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.26.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.27.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (0.1.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.9)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.2)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install autogluon.tabular[all]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "WrWWkHLfgI7b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('clean_Walmart.csv')"
      ],
      "metadata": {
        "id": "08V1BVfbgI89"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "fGIT0feGgJCX",
        "outputId": "60e08977-ddac-44a7-a5ff-66df58af0fd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Store_0  Store_1  Store_2  Store_3  Store_4  Store_5        Date  \\\n",
              "0        0        0        0        0        0        1  2010-02-05   \n",
              "1        0        0        0        0        0        1  2010-02-12   \n",
              "2        0        0        0        0        0        1  2010-02-19   \n",
              "3        0        0        0        0        0        1  2010-02-26   \n",
              "4        0        0        0        0        0        1  2010-03-05   \n",
              "\n",
              "   Weekly_Sales  Holiday_Flag  Temperature  ...  Unemployment  Month  Year  \\\n",
              "0      1.057420             0    -0.995136  ...      0.056964      2  2010   \n",
              "1      1.054348             1    -1.201170  ...      0.056964      2  2010   \n",
              "2      1.001206             0    -1.124178  ...      0.056964      2  2010   \n",
              "3      0.642828             0    -0.760907  ...      0.056964      2  2010   \n",
              "4      0.899914             0    -0.767955  ...      0.056964      3  2010   \n",
              "\n",
              "   Season_0  Season_1  Season_2     Lag_1     Lag_2     Lag_3     Lag_4  \n",
              "0         0         0         1 -1.826402 -1.798349 -1.771203 -1.744944  \n",
              "1         0         0         1  1.060488 -1.798349 -1.771203 -1.744944  \n",
              "2         0         0         1  1.057444  1.063497 -1.771203 -1.744944  \n",
              "3         0         0         1  1.004772  1.060478  1.067142 -1.744944  \n",
              "4         0         1         0  0.649568  1.008264  1.064149  1.071619  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b35545a-4294-46bb-912e-7557c9b99838\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store_0</th>\n",
              "      <th>Store_1</th>\n",
              "      <th>Store_2</th>\n",
              "      <th>Store_3</th>\n",
              "      <th>Store_4</th>\n",
              "      <th>Store_5</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Holiday_Flag</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>...</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>Month</th>\n",
              "      <th>Year</th>\n",
              "      <th>Season_0</th>\n",
              "      <th>Season_1</th>\n",
              "      <th>Season_2</th>\n",
              "      <th>Lag_1</th>\n",
              "      <th>Lag_2</th>\n",
              "      <th>Lag_3</th>\n",
              "      <th>Lag_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>1.057420</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.995136</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.826402</td>\n",
              "      <td>-1.798349</td>\n",
              "      <td>-1.771203</td>\n",
              "      <td>-1.744944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>1.054348</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.201170</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.060488</td>\n",
              "      <td>-1.798349</td>\n",
              "      <td>-1.771203</td>\n",
              "      <td>-1.744944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>1.001206</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.124178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.057444</td>\n",
              "      <td>1.063497</td>\n",
              "      <td>-1.771203</td>\n",
              "      <td>-1.744944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>0.642828</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.760907</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.004772</td>\n",
              "      <td>1.060478</td>\n",
              "      <td>1.067142</td>\n",
              "      <td>-1.744944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>0.899914</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.767955</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.649568</td>\n",
              "      <td>1.008264</td>\n",
              "      <td>1.064149</td>\n",
              "      <td>1.071619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b35545a-4294-46bb-912e-7557c9b99838')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b35545a-4294-46bb-912e-7557c9b99838 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b35545a-4294-46bb-912e-7557c9b99838');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-540091b8-8ff9-463d-ba98-b829b7d75e84\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-540091b8-8ff9-463d-ba98-b829b7d75e84')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-540091b8-8ff9-463d-ba98-b829b7d75e84 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.columns.drop(['Weekly_Sales','Date','Year'])\n",
        "target = 'Weekly_Sales'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y,random_state=42 ,  test_size=0.2)"
      ],
      "metadata": {
        "id": "_cWGdILqgJDt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# Merge X and y for AutoGluon (Train Set)\n",
        "train_data = X_train.copy()\n",
        "train_data['Weekly_Sales'] = y_train  # Add target column\n",
        "\n",
        "# Merge X and y for AutoGluon (Test Set)\n",
        "test_data = X_test.copy()\n",
        "test_data['Weekly_Sales'] = y_test  # Add target column"
      ],
      "metadata": {
        "id": "F6GmnR5RgJIN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AutoGluon predictor\n",
        "predictor = TabularPredictor(label='Weekly_Sales', eval_metric='mean_absolute_error')\n",
        "\n",
        "# Train the model (AutoML handles model selection & hyperparameter tuning)\n",
        "predictor.fit(train_data, presets='best_quality', time_limit=1000)  # Adjust time_limit as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFatEvPUgJJq",
        "outputId": "75e3358f-f029-473c-c077-e26acd21fe65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250213_181300\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.12 GB / 12.67 GB (87.7%)\n",
            "Disk Space Avail:   73.66 GB / 107.72 GB (68.4%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 250s of the 1000s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2025-02-13 18:13:05,605\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20250213_181300/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Beginning AutoGluon training ... Time limit = 243s\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m AutoGluon will save models to \"/content/AutogluonModels/ag-20250213_181300/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Train Data Rows:    4576\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Train Data Columns: 19\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Label Column:       Weekly_Sales\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Problem Type:       regression\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tAvailable Memory:                    10927.64 MB\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.66 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('float', []) :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('int', [])   : 11 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('float', [])     :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('int', [])       :  1 | ['Month']\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('int', ['bool']) : 10 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t19 features in original data used to generate 19 features in processed data.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Data preprocessing and feature engineering runtime = 0.07s ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 161.78s of the 242.73s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1458\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.07s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 155.53s of the 236.47s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1394\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 155.41s of the 236.35s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=3724)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3724)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=3724)\u001b[0m [1000]\tvalid_set's l1: 0.105882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3852)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3852)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=3852)\u001b[0m [1000]\tvalid_set's l1: 0.109198\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m [3000]\tvalid_set's l1: 0.0879233\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m [6000]\tvalid_set's l1: 0.0863904\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m [9000]\tvalid_set's l1: 0.0862998\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m [1000]\tvalid_set's l1: 0.0953431\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m [4000]\tvalid_set's l1: 0.0938135\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m [1000]\tvalid_set's l1: 0.101309\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0987\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t70.57s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t4.41s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 81.22s of the 162.16s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=4288)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4288)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4288)\u001b[0m [1000]\tvalid_set's l1: 0.10497\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m [1000]\tvalid_set's l1: 0.107897\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m [1000]\tvalid_set's l1: 0.0952715\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m [1000]\tvalid_set's l1: 0.100645\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1013\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t44.45s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t1.02s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 33.43s of the 114.38s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1046\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t14.71s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.35s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 18.04s of the 98.98s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\u001b[36m(_ray_fit pid=4812)\u001b[0m \tRan out of time, early stopping on iteration 204.\n",
            "\u001b[36m(_ray_fit pid=4904)\u001b[0m \tRan out of time, early stopping on iteration 381.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5008)\u001b[0m \tRan out of time, early stopping on iteration 179.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5113)\u001b[0m \tRan out of time, early stopping on iteration 369.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1063\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t28.09s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 242.74s of the 67.37s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.429, 'LightGBM_BAG_L1': 0.238, 'RandomForestMSE_BAG_L1': 0.238, 'CatBoost_BAG_L1': 0.095}\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0935\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.29s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 67.06s of the 66.97s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=5105)\u001b[0m \tRan out of time, early stopping on iteration 384.\n",
            "\u001b[36m(_ray_fit pid=5215)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5215)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5317)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5317)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m [1000]\tvalid_set's l1: 0.106441\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m [3000]\tvalid_set's l1: 0.0987497\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m \tRan out of time, early stopping on iteration 4560. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m \t[4529]\tvalid_set's l1: 0.0981923\n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0981\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t40.35s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t1.22s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 22.36s of the 22.27s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=5654)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5654)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5760)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5760)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5889)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5889)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5989)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5989)\u001b[0m \n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0972\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t32.12s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.12s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 242.74s of the -14.61s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.4, 'LightGBMXT_BAG_L2': 0.3, 'RandomForestMSE_BAG_L1': 0.2, 'CatBoost_BAG_L1': 0.1}\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0942\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.15s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m AutoGluon training complete, total runtime = 257.59s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 102.7 rows/s (572 batch size)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250213_181300/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                    model  score_holdout  score_val          eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0     WeightedEnsemble_L3      -0.092356  -0.094201  mean_absolute_error        7.042497       7.382430  230.473738                 0.002915                0.003277           0.149343            3       True         10\n",
            "1     WeightedEnsemble_L2      -0.093140  -0.093531  mean_absolute_error        6.059964       5.876589  158.116821                 0.003190                0.001211           0.287623            2       True          7\n",
            "2       LightGBMXT_BAG_L2      -0.093413  -0.098068  mean_absolute_error        6.945030       7.263591  198.202706                 0.737221                1.220021          40.345644            2       True          8\n",
            "3         LightGBM_BAG_L2      -0.093595  -0.097153  mean_absolute_error        6.302361       6.159132  189.978751                 0.094552                0.115561          32.121689            2       True          9\n",
            "4         LightGBM_BAG_L1      -0.095283  -0.101257  mean_absolute_error        0.696815       1.021279   44.452967                 0.696815                1.021279          44.452967            1       True          4\n",
            "5       LightGBMXT_BAG_L1      -0.095865  -0.098702  mean_absolute_error        4.701952       4.407562   70.571483                 4.701952                4.407562          70.571483            1       True          3\n",
            "6         CatBoost_BAG_L1      -0.105394  -0.106326  mean_absolute_error        0.359226       0.097126   28.092817                 0.359226                0.097126          28.092817            1       True          6\n",
            "7  RandomForestMSE_BAG_L1      -0.108239  -0.104628  mean_absolute_error        0.298781       0.349410   14.711930                 0.298781                0.349410          14.711930            1       True          5\n",
            "8   KNeighborsDist_BAG_L1      -0.135506  -0.139362  mean_absolute_error        0.071805       0.096786    0.013486                 0.071805                0.096786           0.013486            1       True          2\n",
            "9   KNeighborsUnif_BAG_L1      -0.142691  -0.145804  mean_absolute_error        0.079230       0.071407    0.014379                 0.079230                0.071407           0.014379            1       True          1\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t274s\t = DyStack   runtime |\t726s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 726s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250213_181300\"\n",
            "Train Data Rows:    5148\n",
            "Train Data Columns: 19\n",
            "Label Column:       Weekly_Sales\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10792.45 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.75 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\t\t('int', [])   : 11 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\t\t('int', [])       :  1 | ['Month']\n",
            "\t\t('int', ['bool']) : 10 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.40 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.28s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 483.44s of the 725.30s of remaining time.\n",
            "\t-0.1408\t = Validation score   (-mean_absolute_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 479.46s of the 721.32s of remaining time.\n",
            "\t-0.135\t = Validation score   (-mean_absolute_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 479.26s of the 721.12s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-0.0948\t = Validation score   (-mean_absolute_error)\n",
            "\t67.52s\t = Training   runtime\n",
            "\t3.48s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 406.65s of the 648.51s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-0.0959\t = Validation score   (-mean_absolute_error)\n",
            "\t47.59s\t = Training   runtime\n",
            "\t1.58s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 353.70s of the 595.56s of remaining time.\n",
            "\t-0.1031\t = Validation score   (-mean_absolute_error)\n",
            "\t16.45s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 336.23s of the 578.09s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\t-0.0875\t = Validation score   (-mean_absolute_error)\n",
            "\t282.43s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 43.81s of the 285.67s of remaining time.\n",
            "\t-0.1032\t = Validation score   (-mean_absolute_error)\n",
            "\t5.46s\t = Training   runtime\n",
            "\t0.54s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 37.25s of the 279.11s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\t-0.1152\t = Validation score   (-mean_absolute_error)\n",
            "\t72.91s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 202.25s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.625, 'LightGBMXT_BAG_L1': 0.125, 'LightGBM_BAG_L1': 0.125, 'NeuralNetFastAI_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.042}\n",
            "\t-0.0861\t = Validation score   (-mean_absolute_error)\n",
            "\t0.16s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 202.06s of the 202.01s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
            "\t-0.0916\t = Validation score   (-mean_absolute_error)\n",
            "\t71.47s\t = Training   runtime\n",
            "\t7.57s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 123.61s of the 123.56s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
            "\t-0.092\t = Validation score   (-mean_absolute_error)\n",
            "\t36.04s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 83.39s of the 83.35s of remaining time.\n",
            "\t-0.0888\t = Validation score   (-mean_absolute_error)\n",
            "\t29.98s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 52.65s of the 52.60s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
            "\t-0.0895\t = Validation score   (-mean_absolute_error)\n",
            "\t53.87s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -4.97s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.455, 'RandomForestMSE_BAG_L2': 0.182, 'LightGBMXT_BAG_L2': 0.136, 'CatBoost_BAG_L2': 0.136, 'LightGBMXT_BAG_L1': 0.045, 'NeuralNetFastAI_BAG_L1': 0.045}\n",
            "\t-0.0855\t = Validation score   (-mean_absolute_error)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 730.82s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 48.3 rows/s (644 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250213_181300\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7ab51213fe10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "performance = predictor.evaluate(test_data)\n",
        "print(\"Model Performance:\", performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIWwRrHHky8i",
        "outputId": "63f4994f-6221-4373-f62d-97069b7f7cc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance: {'mean_absolute_error': -0.08311138690249001, 'root_mean_squared_error': -0.1340431257400027, 'mean_squared_error': -0.017967559558150176, 'r2': 0.9822384873089811, 'pearsonr': 0.9910929336589572, 'median_absolute_error': -0.0503614785975004}\n"
          ]
        }
      ]
    }
  ]
}