{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOutp+uVC5vmlBp4tG2lLwg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yousrabougara/WalmartSalesForecasting/blob/main/Autogluon_Tabular_LagFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0KgIM2TeMy1",
        "outputId": "c7aaf872-2049-4326-bb8f-53d282ba445b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogluon.tabular[all] in /usr/local/lib/python3.11/dist-packages (1.2)\n",
            "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.13.1)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.5.3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.5.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (3.4.2)\n",
            "Requirement already satisfied: autogluon.core==1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.2)\n",
            "Requirement already satisfied: autogluon.features==1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.2)\n",
            "Requirement already satisfied: catboost<1.3,>=1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.2.7)\n",
            "Requirement already satisfied: spacy<3.8 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (3.7.5)\n",
            "Requirement already satisfied: lightgbm<4.6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (4.5.0)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (0.8.0)\n",
            "Requirement already satisfied: xgboost<2.2,>=1.6 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.1.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.7.18)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (0.28.1)\n",
            "Requirement already satisfied: torch<2.6,>=2.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (3.10.0)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (1.36.19)\n",
            "Requirement already satisfied: autogluon.common==1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (1.2)\n",
            "Requirement already satisfied: ray<2.40,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.39.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (17.0.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.2.7)\n",
            "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.tabular[all]) (5.9.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (1.17.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.7.29)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.20.1+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (6.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: safetensors[torch] in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.37.0,>=1.36.19 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all]) (1.36.19)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all]) (0.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.10.9.7)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (3.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (8.1.8)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.21.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.25.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.5.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.11.12)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.11.4)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.21.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (7.1.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (20.29.2)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.70.0)\n",
            "Requirement already satisfied: memray in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.15.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.6.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]) (0.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8->autogluon.tabular[all]) (3.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.4.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (25.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.18.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.17.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.3.6)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.22.3)\n",
            "Requirement already satisfied: textual>=0.41.0 in /usr/local/lib/python3.11/dist-packages (from memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.19.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.26.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.27.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (0.1.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.9)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.2)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install autogluon.tabular[all]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "WrWWkHLfgI7b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('clean_Walmart.csv')"
      ],
      "metadata": {
        "id": "08V1BVfbgI89"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "fGIT0feGgJCX",
        "outputId": "60e08977-ddac-44a7-a5ff-66df58af0fd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Store_0  Store_1  Store_2  Store_3  Store_4  Store_5        Date  \\\n",
              "0        0        0        0        0        0        1  2010-02-05   \n",
              "1        0        0        0        0        0        1  2010-02-12   \n",
              "2        0        0        0        0        0        1  2010-02-19   \n",
              "3        0        0        0        0        0        1  2010-02-26   \n",
              "4        0        0        0        0        0        1  2010-03-05   \n",
              "\n",
              "   Weekly_Sales  Holiday_Flag  Temperature  ...  Unemployment  Month  Year  \\\n",
              "0      1.057420             0    -0.995136  ...      0.056964      2  2010   \n",
              "1      1.054348             1    -1.201170  ...      0.056964      2  2010   \n",
              "2      1.001206             0    -1.124178  ...      0.056964      2  2010   \n",
              "3      0.642828             0    -0.760907  ...      0.056964      2  2010   \n",
              "4      0.899914             0    -0.767955  ...      0.056964      3  2010   \n",
              "\n",
              "   Season_0  Season_1  Season_2     Lag_1     Lag_2     Lag_3     Lag_4  \n",
              "0         0         0         1 -1.826402 -1.798349 -1.771203 -1.744944  \n",
              "1         0         0         1  1.060488 -1.798349 -1.771203 -1.744944  \n",
              "2         0         0         1  1.057444  1.063497 -1.771203 -1.744944  \n",
              "3         0         0         1  1.004772  1.060478  1.067142 -1.744944  \n",
              "4         0         1         0  0.649568  1.008264  1.064149  1.071619  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b35545a-4294-46bb-912e-7557c9b99838\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store_0</th>\n",
              "      <th>Store_1</th>\n",
              "      <th>Store_2</th>\n",
              "      <th>Store_3</th>\n",
              "      <th>Store_4</th>\n",
              "      <th>Store_5</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Holiday_Flag</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>...</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>Month</th>\n",
              "      <th>Year</th>\n",
              "      <th>Season_0</th>\n",
              "      <th>Season_1</th>\n",
              "      <th>Season_2</th>\n",
              "      <th>Lag_1</th>\n",
              "      <th>Lag_2</th>\n",
              "      <th>Lag_3</th>\n",
              "      <th>Lag_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>1.057420</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.995136</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.826402</td>\n",
              "      <td>-1.798349</td>\n",
              "      <td>-1.771203</td>\n",
              "      <td>-1.744944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>1.054348</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.201170</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.060488</td>\n",
              "      <td>-1.798349</td>\n",
              "      <td>-1.771203</td>\n",
              "      <td>-1.744944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>1.001206</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.124178</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.057444</td>\n",
              "      <td>1.063497</td>\n",
              "      <td>-1.771203</td>\n",
              "      <td>-1.744944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>0.642828</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.760907</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.004772</td>\n",
              "      <td>1.060478</td>\n",
              "      <td>1.067142</td>\n",
              "      <td>-1.744944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>0.899914</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.767955</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.649568</td>\n",
              "      <td>1.008264</td>\n",
              "      <td>1.064149</td>\n",
              "      <td>1.071619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b35545a-4294-46bb-912e-7557c9b99838')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b35545a-4294-46bb-912e-7557c9b99838 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b35545a-4294-46bb-912e-7557c9b99838');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-540091b8-8ff9-463d-ba98-b829b7d75e84\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-540091b8-8ff9-463d-ba98-b829b7d75e84')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-540091b8-8ff9-463d-ba98-b829b7d75e84 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.columns.drop(['Weekly_Sales','Date','Year'])\n",
        "target = 'Weekly_Sales'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y,random_state=42 ,  test_size=0.2)"
      ],
      "metadata": {
        "id": "_cWGdILqgJDt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# Merge X and y for AutoGluon (Train Set)\n",
        "train_data = X_train.copy()\n",
        "train_data['Weekly_Sales'] = y_train  # Add target column\n",
        "\n",
        "# Merge X and y for AutoGluon (Test Set)\n",
        "test_data = X_test.copy()\n",
        "test_data['Weekly_Sales'] = y_test  # Add target column"
      ],
      "metadata": {
        "id": "F6GmnR5RgJIN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AutoGluon predictor\n",
        "predictor = TabularPredictor(label='Weekly_Sales', eval_metric='mean_absolute_error')\n",
        "\n",
        "# Train the model (AutoML handles model selection & hyperparameter tuning)\n",
        "predictor.fit(train_data, presets='best_quality', time_limit=1000)  # Adjust time_limit as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFatEvPUgJJq",
        "outputId": "75e3358f-f029-473c-c077-e26acd21fe65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250213_181300\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.12 GB / 12.67 GB (87.7%)\n",
            "Disk Space Avail:   73.66 GB / 107.72 GB (68.4%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 250s of the 1000s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2025-02-13 18:13:05,605\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20250213_181300/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Beginning AutoGluon training ... Time limit = 243s\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m AutoGluon will save models to \"/content/AutogluonModels/ag-20250213_181300/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Train Data Rows:    4576\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Train Data Columns: 19\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Label Column:       Weekly_Sales\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Problem Type:       regression\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tAvailable Memory:                    10927.64 MB\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.66 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('float', []) :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('int', [])   : 11 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('float', [])     :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('int', [])       :  1 | ['Month']\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t\t('int', ['bool']) : 10 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t19 features in original data used to generate 19 features in processed data.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Data preprocessing and feature engineering runtime = 0.07s ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 161.78s of the 242.73s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1458\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.07s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 155.53s of the 236.47s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1394\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 155.41s of the 236.35s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3725)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=3724)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3724)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=3724)\u001b[0m [1000]\tvalid_set's l1: 0.105882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3852)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3852)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=3852)\u001b[0m [1000]\tvalid_set's l1: 0.109198\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m [3000]\tvalid_set's l1: 0.0879233\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m [6000]\tvalid_set's l1: 0.0863904\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3853)\u001b[0m [9000]\tvalid_set's l1: 0.0862998\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3996)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4121)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m [1000]\tvalid_set's l1: 0.0953431\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4077)\u001b[0m [4000]\tvalid_set's l1: 0.0938135\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4208)\u001b[0m [1000]\tvalid_set's l1: 0.101309\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0987\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t70.57s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t4.41s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 81.22s of the 162.16s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4289)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=4288)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4288)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4288)\u001b[0m [1000]\tvalid_set's l1: 0.10497\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4385)\u001b[0m [1000]\tvalid_set's l1: 0.107897\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4446)\u001b[0m [1000]\tvalid_set's l1: 0.0952715\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4497)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4609)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4559)\u001b[0m [1000]\tvalid_set's l1: 0.100645\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=4682)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1013\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t44.45s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t1.02s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 33.43s of the 114.38s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1046\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t14.71s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.35s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 18.04s of the 98.98s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\u001b[36m(_ray_fit pid=4812)\u001b[0m \tRan out of time, early stopping on iteration 204.\n",
            "\u001b[36m(_ray_fit pid=4904)\u001b[0m \tRan out of time, early stopping on iteration 381.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5008)\u001b[0m \tRan out of time, early stopping on iteration 179.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5113)\u001b[0m \tRan out of time, early stopping on iteration 369.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.1063\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t28.09s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 242.74s of the 67.37s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.429, 'LightGBM_BAG_L1': 0.238, 'RandomForestMSE_BAG_L1': 0.238, 'CatBoost_BAG_L1': 0.095}\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0935\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.29s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 67.06s of the 66.97s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5214)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=5105)\u001b[0m \tRan out of time, early stopping on iteration 384.\n",
            "\u001b[36m(_ray_fit pid=5215)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5215)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5314)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5317)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5317)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_ray_fit pid=5409)\u001b[0m [1000]\tvalid_set's l1: 0.106441\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m [3000]\tvalid_set's l1: 0.0987497\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5527)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m \tRan out of time, early stopping on iteration 4560. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=5410)\u001b[0m \t[4529]\tvalid_set's l1: 0.0981923\n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=5594)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0981\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t40.35s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t1.22s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 22.36s of the 22.27s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5653)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=5654)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5654)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5753)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5760)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5760)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5852)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5889)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5889)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5952)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=5989)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=5989)\u001b[0m \n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0972\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t32.12s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.12s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 242.74s of the -14.61s of remaining time.\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.4, 'LightGBMXT_BAG_L2': 0.3, 'RandomForestMSE_BAG_L1': 0.2, 'CatBoost_BAG_L1': 0.1}\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t-0.0942\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.15s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m AutoGluon training complete, total runtime = 257.59s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 102.7 rows/s (572 batch size)\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250213_181300/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m \n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=3548)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                    model  score_holdout  score_val          eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0     WeightedEnsemble_L3      -0.092356  -0.094201  mean_absolute_error        7.042497       7.382430  230.473738                 0.002915                0.003277           0.149343            3       True         10\n",
            "1     WeightedEnsemble_L2      -0.093140  -0.093531  mean_absolute_error        6.059964       5.876589  158.116821                 0.003190                0.001211           0.287623            2       True          7\n",
            "2       LightGBMXT_BAG_L2      -0.093413  -0.098068  mean_absolute_error        6.945030       7.263591  198.202706                 0.737221                1.220021          40.345644            2       True          8\n",
            "3         LightGBM_BAG_L2      -0.093595  -0.097153  mean_absolute_error        6.302361       6.159132  189.978751                 0.094552                0.115561          32.121689            2       True          9\n",
            "4         LightGBM_BAG_L1      -0.095283  -0.101257  mean_absolute_error        0.696815       1.021279   44.452967                 0.696815                1.021279          44.452967            1       True          4\n",
            "5       LightGBMXT_BAG_L1      -0.095865  -0.098702  mean_absolute_error        4.701952       4.407562   70.571483                 4.701952                4.407562          70.571483            1       True          3\n",
            "6         CatBoost_BAG_L1      -0.105394  -0.106326  mean_absolute_error        0.359226       0.097126   28.092817                 0.359226                0.097126          28.092817            1       True          6\n",
            "7  RandomForestMSE_BAG_L1      -0.108239  -0.104628  mean_absolute_error        0.298781       0.349410   14.711930                 0.298781                0.349410          14.711930            1       True          5\n",
            "8   KNeighborsDist_BAG_L1      -0.135506  -0.139362  mean_absolute_error        0.071805       0.096786    0.013486                 0.071805                0.096786           0.013486            1       True          2\n",
            "9   KNeighborsUnif_BAG_L1      -0.142691  -0.145804  mean_absolute_error        0.079230       0.071407    0.014379                 0.079230                0.071407           0.014379            1       True          1\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t274s\t = DyStack   runtime |\t726s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 726s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250213_181300\"\n",
            "Train Data Rows:    5148\n",
            "Train Data Columns: 19\n",
            "Label Column:       Weekly_Sales\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10792.45 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.75 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\t\t('int', [])   : 11 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\t\t('int', [])       :  1 | ['Month']\n",
            "\t\t('int', ['bool']) : 10 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.40 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.28s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 483.44s of the 725.30s of remaining time.\n",
            "\t-0.1408\t = Validation score   (-mean_absolute_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 479.46s of the 721.32s of remaining time.\n",
            "\t-0.135\t = Validation score   (-mean_absolute_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 479.26s of the 721.12s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-0.0948\t = Validation score   (-mean_absolute_error)\n",
            "\t67.52s\t = Training   runtime\n",
            "\t3.48s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 406.65s of the 648.51s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-0.0959\t = Validation score   (-mean_absolute_error)\n",
            "\t47.59s\t = Training   runtime\n",
            "\t1.58s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 353.70s of the 595.56s of remaining time.\n",
            "\t-0.1031\t = Validation score   (-mean_absolute_error)\n",
            "\t16.45s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 336.23s of the 578.09s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\t-0.0875\t = Validation score   (-mean_absolute_error)\n",
            "\t282.43s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 43.81s of the 285.67s of remaining time.\n",
            "\t-0.1032\t = Validation score   (-mean_absolute_error)\n",
            "\t5.46s\t = Training   runtime\n",
            "\t0.54s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 37.25s of the 279.11s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\t-0.1152\t = Validation score   (-mean_absolute_error)\n",
            "\t72.91s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 202.25s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.625, 'LightGBMXT_BAG_L1': 0.125, 'LightGBM_BAG_L1': 0.125, 'NeuralNetFastAI_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.042}\n",
            "\t-0.0861\t = Validation score   (-mean_absolute_error)\n",
            "\t0.16s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 202.06s of the 202.01s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
            "\t-0.0916\t = Validation score   (-mean_absolute_error)\n",
            "\t71.47s\t = Training   runtime\n",
            "\t7.57s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 123.61s of the 123.56s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
            "\t-0.092\t = Validation score   (-mean_absolute_error)\n",
            "\t36.04s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 83.39s of the 83.35s of remaining time.\n",
            "\t-0.0888\t = Validation score   (-mean_absolute_error)\n",
            "\t29.98s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 52.65s of the 52.60s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
            "\t-0.0895\t = Validation score   (-mean_absolute_error)\n",
            "\t53.87s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -4.97s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.455, 'RandomForestMSE_BAG_L2': 0.182, 'LightGBMXT_BAG_L2': 0.136, 'CatBoost_BAG_L2': 0.136, 'LightGBMXT_BAG_L1': 0.045, 'NeuralNetFastAI_BAG_L1': 0.045}\n",
            "\t-0.0855\t = Validation score   (-mean_absolute_error)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 730.82s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 48.3 rows/s (644 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250213_181300\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7ab51213fe10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "performance = predictor.evaluate(test_data)\n",
        "print(\"Model Performance:\", performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIWwRrHHky8i",
        "outputId": "63f4994f-6221-4373-f62d-97069b7f7cc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance: {'mean_absolute_error': -0.08311138690249001, 'root_mean_squared_error': -0.1340431257400027, 'mean_squared_error': -0.017967559558150176, 'r2': 0.9822384873089811, 'pearsonr': 0.9910929336589572, 'median_absolute_error': -0.0503614785975004}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AutoGluon predictor\n",
        "predictor = TabularPredictor(label='Weekly_Sales', eval_metric='mean_absolute_error')\n",
        "\n",
        "# Train the model (AutoML handles model selection & hyperparameter tuning)\n",
        "predictor.fit(train_data, presets='high_quality', time_limit=2000)  # Adjust time_limit as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spmhd0xQlnUa",
        "outputId": "c19d208b-3bf3-4470-b20a-254b6f7c2de1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250213_183456\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.28 GB / 12.67 GB (81.1%)\n",
            "Disk Space Avail:   73.05 GB / 107.72 GB (67.8%)\n",
            "===================================================\n",
            "Presets specified: ['high_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
            "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 500s of the 2000s of remaining time (25%).\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20250213_183456/ds_sub_fit/sub_fit_ho\"\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                          model  score_holdout  score_val          eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      WeightedEnsemble_L3_FULL      -0.086726  -0.088971  mean_absolute_error        1.320341            NaN  76.891267                 0.003609                     NaN           0.150550            3       True         13\n",
            "1      WeightedEnsemble_L2_FULL      -0.088762  -0.089554  mean_absolute_error        0.630050            NaN  28.540879                 0.004284                     NaN           0.383781            2       True          9\n",
            "2          CatBoost_BAG_L1_FULL      -0.089009  -0.091250  mean_absolute_error        0.011038            NaN  14.466571                 0.011038                     NaN          14.466571            1       True          6\n",
            "3   RandomForestMSE_BAG_L2_FULL      -0.090675  -0.091319  mean_absolute_error        1.082379            NaN  71.740622                 0.181476                0.357723          25.877083            2       True         12\n",
            "4          LightGBM_BAG_L2_FULL      -0.092761  -0.095296  mean_absolute_error        0.913817            NaN  46.450892                 0.012914                     NaN           0.587353            2       True         11\n",
            "5        LightGBMXT_BAG_L2_FULL      -0.092857  -0.095706  mean_absolute_error        1.135256            NaN  50.863633                 0.234353                     NaN           5.000094            2       True         10\n",
            "6          LightGBM_BAG_L1_FULL      -0.095967  -0.101257  mean_absolute_error        0.093102            NaN   1.375359                 0.093102                     NaN           1.375359            1       True          4\n",
            "7        LightGBMXT_BAG_L1_FULL      -0.099084  -0.098702  mean_absolute_error        0.327420            NaN   7.254704                 0.327420                     NaN           7.254704            1       True          3\n",
            "8     ExtraTreesMSE_BAG_L1_FULL      -0.107588  -0.103303  mean_absolute_error        0.194207       0.351874   5.060464                 0.194207                0.351874           5.060464            1       True          7\n",
            "9   RandomForestMSE_BAG_L1_FULL      -0.108239  -0.104628  mean_absolute_error        0.211802       0.470204  16.046622                 0.211802                0.470204          16.046622            1       True          5\n",
            "10   KNeighborsDist_BAG_L1_FULL      -0.135506  -0.139362  mean_absolute_error        0.017500       0.079730   0.009933                 0.017500                0.079730           0.009933            1       True          2\n",
            "11   KNeighborsUnif_BAG_L1_FULL      -0.142691  -0.145804  mean_absolute_error        0.016515       0.089230   0.012712                 0.016515                0.089230           0.012712            1       True          1\n",
            "12  NeuralNetFastAI_BAG_L1_FULL      -0.148406  -0.145620  mean_absolute_error        0.029320            NaN   1.637174                 0.029320                     NaN           1.637174            1       True          8\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t550s\t = DyStack   runtime |\t1450s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 1450s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250213_183456\"\n",
            "Train Data Rows:    5148\n",
            "Train Data Columns: 19\n",
            "Label Column:       Weekly_Sales\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10197.39 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.75 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\t\t('int', [])   : 11 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\t\t('int', [])       :  1 | ['Month']\n",
            "\t\t('int', ['bool']) : 10 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.40 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.26s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 965.95s of the 1449.23s of remaining time.\n",
            "\t-0.1408\t = Validation score   (-mean_absolute_error)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 965.72s of the 1449.00s of remaining time.\n",
            "\t-0.135\t = Validation score   (-mean_absolute_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 965.52s of the 1448.80s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-0.0948\t = Validation score   (-mean_absolute_error)\n",
            "\t68.48s\t = Training   runtime\n",
            "\t3.9s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 892.33s of the 1375.61s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-0.0959\t = Validation score   (-mean_absolute_error)\n",
            "\t48.48s\t = Training   runtime\n",
            "\t1.25s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 839.60s of the 1322.89s of remaining time.\n",
            "\t-0.1031\t = Validation score   (-mean_absolute_error)\n",
            "\t16.85s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 822.04s of the 1305.32s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\t-0.0869\t = Validation score   (-mean_absolute_error)\n",
            "\t672.48s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 145.87s of the 629.15s of remaining time.\n",
            "\t-0.1032\t = Validation score   (-mean_absolute_error)\n",
            "\t6.97s\t = Training   runtime\n",
            "\t0.39s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 138.19s of the 621.47s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-0.101\t = Validation score   (-mean_absolute_error)\n",
            "\t92.02s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 42.35s of the 525.64s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
            "\t-0.0928\t = Validation score   (-mean_absolute_error)\n",
            "\t44.24s\t = Training   runtime\n",
            "\t1.04s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 475.30s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.545, 'NeuralNetFastAI_BAG_L1': 0.182, 'XGBoost_BAG_L1': 0.136, 'LightGBMXT_BAG_L1': 0.091, 'LightGBM_BAG_L1': 0.045}\n",
            "\t-0.0848\t = Validation score   (-mean_absolute_error)\n",
            "\t0.12s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 475.14s of the 475.08s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n",
            "\t-0.092\t = Validation score   (-mean_absolute_error)\n",
            "\t58.62s\t = Training   runtime\n",
            "\t2.74s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 409.20s of the 409.14s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\t-0.0904\t = Validation score   (-mean_absolute_error)\n",
            "\t33.6s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 370.37s of the 370.30s of remaining time.\n",
            "\t-0.0874\t = Validation score   (-mean_absolute_error)\n",
            "\t31.81s\t = Training   runtime\n",
            "\t0.56s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 337.56s of the 337.50s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.13%)\n",
            "\t-0.0884\t = Validation score   (-mean_absolute_error)\n",
            "\t96.41s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 236.09s of the 236.03s of remaining time.\n",
            "\t-0.0857\t = Validation score   (-mean_absolute_error)\n",
            "\t8.71s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 226.69s of the 226.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-0.0916\t = Validation score   (-mean_absolute_error)\n",
            "\t90.24s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 132.36s of the 132.29s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.16%)\n",
            "\t-0.0877\t = Validation score   (-mean_absolute_error)\n",
            "\t33.31s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 93.79s of the 93.73s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\t-0.0936\t = Validation score   (-mean_absolute_error)\n",
            "\t110.52s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -23.73s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.368, 'ExtraTreesMSE_BAG_L2': 0.368, 'NeuralNetFastAI_BAG_L1': 0.105, 'LightGBMXT_BAG_L1': 0.053, 'XGBoost_BAG_L1': 0.053, 'CatBoost_BAG_L2': 0.053}\n",
            "\t-0.0842\t = Validation score   (-mean_absolute_error)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 1473.6s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 94.0 rows/s (644 batch size)\n",
            "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\t6.98s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\t1.92s\t = Training   runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t16.85s\t = Training   runtime\n",
            "\t0.38s\t = Validation runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: CatBoost_BAG_L1_FULL ...\n",
            "\t50.3s\t = Training   runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t6.97s\t = Training   runtime\n",
            "\t0.39s\t = Validation runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
            "No improvement since epoch 1: early stopping\n",
            "\t4.84s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost_BAG_L1_FULL ...\n",
            "\t2.17s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.545, 'NeuralNetFastAI_BAG_L1': 0.182, 'XGBoost_BAG_L1': 0.136, 'LightGBMXT_BAG_L1': 0.091, 'LightGBM_BAG_L1': 0.045}\n",
            "\t0.12s\t = Training   runtime\n",
            "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
            "\t3.86s\t = Training   runtime\n",
            "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_BAG_L2_FULL ...\n",
            "\t0.69s\t = Training   runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t31.81s\t = Training   runtime\n",
            "\t0.56s\t = Validation runtime\n",
            "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: CatBoost_BAG_L2_FULL ...\n",
            "\t5.73s\t = Training   runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t8.71s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 28.\n",
            "\t7.61s\t = Training   runtime\n",
            "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost_BAG_L2_FULL ...\n",
            "\t0.37s\t = Training   runtime\n",
            "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
            "\t7.59s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.368, 'ExtraTreesMSE_BAG_L2': 0.368, 'NeuralNetFastAI_BAG_L1': 0.105, 'LightGBMXT_BAG_L1': 0.053, 'XGBoost_BAG_L1': 0.053, 'CatBoost_BAG_L2': 0.053}\n",
            "\t0.27s\t = Training   runtime\n",
            "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 95.43s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250213_183456\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7ab3251eee90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "performance = predictor.evaluate(test_data)\n",
        "print(\"Model Performance:\", performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBAe1rJylp_t",
        "outputId": "962ed684-15e8-46ff-dd87-a47f6e968b72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance: {'mean_absolute_error': -0.09001234656577138, 'root_mean_squared_error': -0.14068545713489408, 'mean_squared_error': -0.01979239784925412, 'r2': 0.9804345757448312, 'pearsonr': 0.9902066300925594, 'median_absolute_error': -0.05467851115944233}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AutoGluon predictor\n",
        "predictor = TabularPredictor(label='Weekly_Sales', eval_metric='mean_absolute_error')\n",
        "\n",
        "# Train the model (AutoML handles model selection & hyperparameter tuning)\n",
        "predictor.fit(train_data, presets='best_quality', time_limit=2500)  # Adjust time_limit as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPuqTEnsur8z",
        "outputId": "8fee0b41-c208-40ab-ef67-7f7cb615b68e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250213_191708\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.50 GB / 12.67 GB (75.0%)\n",
            "Disk Space Avail:   71.73 GB / 107.72 GB (66.6%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 625s of the 2500s of remaining time (25%).\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20250213_191708/ds_sub_fit/sub_fit_ho\"\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                     model  score_holdout  score_val          eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      WeightedEnsemble_L3      -0.091203  -0.091853  mean_absolute_error        8.270921       9.020299  476.376477                 0.003504                0.001179           0.120932            3       True         12\n",
            "1          CatBoost_BAG_L2      -0.091324  -0.095317  mean_absolute_error        5.963530       6.796959  402.716649                 0.046116                0.053831          71.147459            2       True         11\n",
            "2      WeightedEnsemble_L2      -0.091724  -0.092461  mean_absolute_error        5.824488       6.601697  331.769307                 0.003437                0.001309           0.221844            2       True          7\n",
            "3          LightGBM_BAG_L2      -0.092496  -0.096381  mean_absolute_error        6.036989       6.871000  366.678370                 0.119576                0.127872          35.109180            2       True          9\n",
            "4   RandomForestMSE_BAG_L2      -0.093582  -0.093774  mean_absolute_error        6.174462       7.319176  356.312417                 0.257049                0.576049          24.743228            2       True         10\n",
            "5        LightGBMXT_BAG_L2      -0.093583  -0.097950  mean_absolute_error        7.964252       8.389240  380.364858                 2.046838                1.646112          48.795669            2       True          8\n",
            "6          LightGBM_BAG_L1      -0.095283  -0.101257  mean_absolute_error        0.727696       0.990634   44.956396                 0.727696                0.990634          44.956396            1       True          4\n",
            "7        LightGBMXT_BAG_L1      -0.095865  -0.098702  mean_absolute_error        4.392406       5.160163  225.966016                 4.392406                5.160163         225.966016            1       True          3\n",
            "8          CatBoost_BAG_L1      -0.096035  -0.097411  mean_absolute_error        0.391959       0.082806   44.640935                 0.391959                0.082806          44.640935            1       True          6\n",
            "9   RandomForestMSE_BAG_L1      -0.108239  -0.104628  mean_absolute_error        0.308990       0.366786   15.984115                 0.308990                0.366786          15.984115            1       True          5\n",
            "10   KNeighborsDist_BAG_L1      -0.135506  -0.139362  mean_absolute_error        0.027847       0.070043    0.009895                 0.027847                0.070043           0.009895            1       True          2\n",
            "11   KNeighborsUnif_BAG_L1      -0.142691  -0.145804  mean_absolute_error        0.068515       0.072696    0.011832                 0.068515                0.072696           0.011832            1       True          1\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t674s\t = DyStack   runtime |\t1826s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 1826s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250213_191708\"\n",
            "Train Data Rows:    5148\n",
            "Train Data Columns: 19\n",
            "Label Column:       Weekly_Sales\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9753.45 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.75 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\t\t('int', [])   : 11 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     :  8 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Lag_1', ...]\n",
            "\t\t('int', [])       :  1 | ['Month']\n",
            "\t\t('int', ['bool']) : 10 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t19 features in original data used to generate 19 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.40 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.21s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1216.92s of the 1825.82s of remaining time.\n",
            "\t-0.1408\t = Validation score   (-mean_absolute_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1216.76s of the 1825.65s of remaining time.\n",
            "\t-0.135\t = Validation score   (-mean_absolute_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1216.55s of the 1825.45s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-0.0948\t = Validation score   (-mean_absolute_error)\n",
            "\t74.81s\t = Training   runtime\n",
            "\t4.7s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1134.42s of the 1743.32s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t-0.0959\t = Validation score   (-mean_absolute_error)\n",
            "\t50.63s\t = Training   runtime\n",
            "\t1.53s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1079.00s of the 1687.90s of remaining time.\n",
            "\t-0.1031\t = Validation score   (-mean_absolute_error)\n",
            "\t17.85s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1060.36s of the 1669.26s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "\t-0.0868\t = Validation score   (-mean_absolute_error)\n",
            "\t863.38s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 193.08s of the 801.97s of remaining time.\n",
            "\t-0.1032\t = Validation score   (-mean_absolute_error)\n",
            "\t5.58s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 186.80s of the 795.70s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-0.101\t = Validation score   (-mean_absolute_error)\n",
            "\t99.02s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 81.68s of the 690.58s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
            "\t-0.0927\t = Validation score   (-mean_absolute_error)\n",
            "\t49.4s\t = Training   runtime\n",
            "\t1.24s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 24.64s of the 633.54s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t-0.1662\t = Validation score   (-mean_absolute_error)\n",
            "\t59.02s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 570.16s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.545, 'NeuralNetFastAI_BAG_L1': 0.182, 'XGBoost_BAG_L1': 0.182, 'LightGBMXT_BAG_L1': 0.091}\n",
            "\t-0.0847\t = Validation score   (-mean_absolute_error)\n",
            "\t0.14s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 570.00s of the 569.94s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "\t-0.0916\t = Validation score   (-mean_absolute_error)\n",
            "\t78.52s\t = Training   runtime\n",
            "\t6.0s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 483.35s of the 483.29s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
            "\t-0.0902\t = Validation score   (-mean_absolute_error)\n",
            "\t38.12s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 440.11s of the 440.05s of remaining time.\n",
            "\t-0.0872\t = Validation score   (-mean_absolute_error)\n",
            "\t34.64s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 404.71s of the 404.65s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
            "\t-0.0884\t = Validation score   (-mean_absolute_error)\n",
            "\t127.09s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 271.63s of the 271.57s of remaining time.\n",
            "\t-0.0857\t = Validation score   (-mean_absolute_error)\n",
            "\t10.08s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 260.81s of the 260.75s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\t-0.0911\t = Validation score   (-mean_absolute_error)\n",
            "\t91.16s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 165.83s of the 165.78s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
            "\t-0.0876\t = Validation score   (-mean_absolute_error)\n",
            "\t44.52s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 114.95s of the 114.89s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\t-0.0936\t = Validation score   (-mean_absolute_error)\n",
            "\t126.1s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -16.24s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.375, 'ExtraTreesMSE_BAG_L2': 0.375, 'NeuralNetFastAI_BAG_L1': 0.125, 'LightGBMXT_BAG_L1': 0.042, 'XGBoost_BAG_L1': 0.042, 'CatBoost_BAG_L2': 0.042}\n",
            "\t-0.0841\t = Validation score   (-mean_absolute_error)\n",
            "\t0.29s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 1842.63s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 77.0 rows/s (644 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250213_191708\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7ab34aa61210>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "performance = predictor.evaluate(test_data)\n",
        "print(\"Model Performance:\", performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6gWNxENuuF8",
        "outputId": "2a95d1c3-0cbf-48ee-e632-4df6c88e5e0f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance: {'mean_absolute_error': -0.08261682572446233, 'root_mean_squared_error': -0.1332409176179073, 'mean_squared_error': -0.017753142127661957, 'r2': 0.9824504458613079, 'pearsonr': 0.9912048639379207, 'median_absolute_error': -0.05042126900473566}\n"
          ]
        }
      ]
    }
  ]
}