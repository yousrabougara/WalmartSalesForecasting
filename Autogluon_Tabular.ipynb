{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHvczJQFDhJEgfCkKpT2Tn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yousrabougara/WalmartSalesForecasting/blob/main/Autogluon_Tabular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhmp-TjKYY7Y",
        "outputId": "384aaf3b-bf4a-4e1d-e32e-563effb7f7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon.tabular[all]\n",
            "  Downloading autogluon.tabular-1.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (1.13.1)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.2.2)\n",
            "Collecting scikit-learn<1.5.3,>=1.4.0 (from autogluon.tabular[all])\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (3.4.2)\n",
            "Collecting autogluon.core==1.2 (from autogluon.tabular[all])\n",
            "  Downloading autogluon.core-1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.2 (from autogluon.tabular[all])\n",
            "  Downloading autogluon.features-1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all])\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: spacy<3.8 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (3.7.5)\n",
            "Requirement already satisfied: lightgbm<4.6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (4.5.0)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (0.8.0)\n",
            "Requirement already satisfied: xgboost<2.2,>=1.6 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.1.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.7.18)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (0.28.1)\n",
            "Requirement already satisfied: torch<2.6,>=2.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.2->autogluon.tabular[all])\n",
            "  Downloading boto3-1.36.19-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting autogluon.common==1.2 (from autogluon.core==1.2->autogluon.tabular[all])\n",
            "  Downloading autogluon.common-1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ray<2.40,>=2.10.0 (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading ray-2.39.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (17.0.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.2.7)\n",
            "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.tabular[all]) (5.9.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (1.17.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.7.29)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.20.1+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (6.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.6,>=2.2->autogluon.tabular[all])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: safetensors[torch] in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]) (0.5.2)\n",
            "Collecting botocore<1.37.0,>=1.36.19 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all])\n",
            "  Downloading botocore-1.36.19-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all])\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.10.9.7)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (3.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (8.1.8)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.25.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.5.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.11.12)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.21.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (7.1.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.70.0)\n",
            "Collecting memray (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading memray-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]) (0.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8->autogluon.tabular[all]) (3.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.4.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (25.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.18.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.17.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.3.6)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.22.3)\n",
            "Collecting textual>=0.41.0 (from memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading textual-1.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all])\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.19.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.26.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.27.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (0.1.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.9)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.2)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.6.1)\n",
            "Downloading autogluon.core-1.2-py3-none-any.whl (266 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.2-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.2-py3-none-any.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.36.19-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.39.0-cp311-cp311-manylinux2014_x86_64.whl (66.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.36.19-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading memray-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading textual-1.0.0-py3-none-any.whl (660 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.5/660.5 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py-spy, opencensus-context, distlib, colorful, virtualenv, tensorboardX, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, catboost, aiohttp-cors, textual, ray, opencensus, boto3, memray, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiohttp-cors-0.7.0 autogluon.common-1.2 autogluon.core-1.2 autogluon.features-1.2 autogluon.tabular-1.2 boto3-1.36.19 botocore-1.36.19 catboost-1.2.7 colorful-0.5.6 distlib-0.3.9 jmespath-1.0.1 memray-1.15.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 py-spy-0.4.0 ray-2.39.0 s3transfer-0.11.2 scikit-learn-1.5.2 tensorboardX-2.6.2.2 textual-1.0.0 virtualenv-20.29.2\n"
          ]
        }
      ],
      "source": [
        "!pip install autogluon.tabular[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "biS4Wy1ZY98a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Preprocessed_Walmart.csv')"
      ],
      "metadata": {
        "id": "ne-ZgabMY7uy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "cjRPlHbqY8hg",
        "outputId": "b2cdaafe-e9a3-4d64-c2e6-796347d57c5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Store_0  Store_1  Store_2  Store_3  Store_4  Store_5        Date  \\\n",
              "0        0        0        0        0        0        1  2010-02-05   \n",
              "1        0        0        0        0        0        1  2010-02-12   \n",
              "2        0        0        0        0        0        1  2010-02-19   \n",
              "3        0        0        0        0        0        1  2010-02-26   \n",
              "4        0        0        0        0        0        1  2010-03-05   \n",
              "\n",
              "   Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price       CPI  \\\n",
              "0      1.057420             0    -0.995136   -1.713800  1.004175   \n",
              "1      1.054348             1    -1.201170   -1.766089  1.007880   \n",
              "2      1.001206             0    -1.124178   -1.840166  1.009074   \n",
              "3      0.642828             0    -0.760907   -1.737766  1.009849   \n",
              "4      0.899914             0    -0.767955   -1.598328  1.010624   \n",
              "\n",
              "   Unemployment  Month  Year  Season_0  Season_1  Season_2  \n",
              "0      0.056964      2  2010         0         0         1  \n",
              "1      0.056964      2  2010         0         0         1  \n",
              "2      0.056964      2  2010         0         0         1  \n",
              "3      0.056964      2  2010         0         0         1  \n",
              "4      0.056964      3  2010         0         1         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c19d596-2ad6-470e-ba4e-88745474cc93\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store_0</th>\n",
              "      <th>Store_1</th>\n",
              "      <th>Store_2</th>\n",
              "      <th>Store_3</th>\n",
              "      <th>Store_4</th>\n",
              "      <th>Store_5</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Holiday_Flag</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>Month</th>\n",
              "      <th>Year</th>\n",
              "      <th>Season_0</th>\n",
              "      <th>Season_1</th>\n",
              "      <th>Season_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>1.057420</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.995136</td>\n",
              "      <td>-1.713800</td>\n",
              "      <td>1.004175</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>1.054348</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.201170</td>\n",
              "      <td>-1.766089</td>\n",
              "      <td>1.007880</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>1.001206</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.124178</td>\n",
              "      <td>-1.840166</td>\n",
              "      <td>1.009074</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>0.642828</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.760907</td>\n",
              "      <td>-1.737766</td>\n",
              "      <td>1.009849</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>0.899914</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.767955</td>\n",
              "      <td>-1.598328</td>\n",
              "      <td>1.010624</td>\n",
              "      <td>0.056964</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c19d596-2ad6-470e-ba4e-88745474cc93')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c19d596-2ad6-470e-ba4e-88745474cc93 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c19d596-2ad6-470e-ba4e-88745474cc93');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-56924028-d90b-4cec-ad1d-d9638a3f856c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56924028-d90b-4cec-ad1d-d9638a3f856c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-56924028-d90b-4cec-ad1d-d9638a3f856c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6435,\n  \"fields\": [\n    {\n      \"column\": \"Store_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Store_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Store_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Store_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Store_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Store_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 143,\n        \"samples\": [\n          \"2012-05-04\",\n          \"2010-06-18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weekly_Sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000777091348265,\n        \"min\": -1.4831558702051406,\n        \"max\": 4.911589119917624,\n        \"num_unique_values\": 6435,\n        \"samples\": [\n          0.1627356673872685,\n          0.4569827882122765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Holiday_Flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000777091348283,\n        \"min\": -3.4008612052424607,\n        \"max\": 2.14038649469432,\n        \"num_unique_values\": 3528,\n        \"samples\": [\n          -0.5169182976139147,\n          2.0324894015155124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fuel_Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000777091348259,\n        \"min\": -1.9316724775927567,\n        \"max\": 2.417062611888811,\n        \"num_unique_values\": 892,\n        \"samples\": [\n          -1.1299016795320274,\n          1.2884830646185448\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CPI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000777091348272,\n        \"min\": -1.1565480975900229,\n        \"max\": 1.414212076185828,\n        \"num_unique_values\": 2145,\n        \"samples\": [\n          0.3312278219230963,\n          1.0807121336504282\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unemployment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0000777091348299,\n        \"min\": -2.196548136731879,\n        \"max\": 3.366059395459284,\n        \"num_unique_values\": 349,\n        \"samples\": [\n          0.0990803886289745,\n          -0.104039552885769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          12,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2010,\n        \"max\": 2012,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2010,\n          2011\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Season_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Season_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Season_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.columns.drop(['Weekly_Sales','Date','Year'])\n",
        "target = 'Weekly_Sales'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y,random_state=42 ,  test_size=0.2)"
      ],
      "metadata": {
        "id": "6fWTd655Y8mP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WtbW6CQSgqy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# Merge X and y for AutoGluon (Train Set)\n",
        "train_data = X_train.copy()\n",
        "train_data['Weekly_Sales'] = y_train  # Add target column\n",
        "\n",
        "# Merge X and y for AutoGluon (Test Set)\n",
        "test_data = X_test.copy()\n",
        "test_data['Weekly_Sales'] = y_test  # Add target column"
      ],
      "metadata": {
        "id": "JN0iLPWQY8np"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AutoGluon predictor\n",
        "predictor = TabularPredictor(label='Weekly_Sales', eval_metric='mean_absolute_error')\n",
        "\n",
        "# Train the model (AutoML handles model selection & hyperparameter tuning)\n",
        "predictor.fit(train_data, presets='best_quality', time_limit=1000)  # Adjust time_limit as needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ucgoiZNY8su",
        "outputId": "24570c6d-70f3-43b5-87c3-1efeaf0b22c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250213_174122\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.21 GB / 12.67 GB (88.4%)\n",
            "Disk Space Avail:   73.86 GB / 107.72 GB (68.6%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 250s of the 1000s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2025-02-13 17:41:30,296\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20250213_174122/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Beginning AutoGluon training ... Time limit = 241s\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m AutoGluon will save models to \"/content/AutogluonModels/ag-20250213_174122/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Train Data Rows:    4576\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Train Data Columns: 15\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Label Column:       Weekly_Sales\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Problem Type:       regression\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tAvailable Memory:                    10918.39 MB\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.52 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\t('float', []) :  4 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\t('int', [])   : 11 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\t('float', [])     :  4 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\t('int', [])       :  1 | ['Month']\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t\t('int', ['bool']) : 10 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t15 features in original data used to generate 15 features in processed data.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.22 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 160.44s of the 240.70s of remaining time.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.8172\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 154.44s of the 234.71s of remaining time.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.8943\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.04s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 154.38s of the 234.65s of remaining time.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\u001b[36m(_ray_fit pid=1753)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=1753)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=1753)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=1753)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=1753)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=1753)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=1753)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=1752)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=1752)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=1752)\u001b[0m [1000]\tvalid_set's l1: 0.111989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=1868)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=1868)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=1868)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=1868)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=1868)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=1868)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=1868)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=1901)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=1901)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=1868)\u001b[0m [1000]\tvalid_set's l1: 0.117874\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=1970)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=1970)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=1970)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=1970)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=1970)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=1970)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=1970)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2008)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2008)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=1970)\u001b[0m [1000]\tvalid_set's l1: 0.11315\n",
            "\u001b[36m(_ray_fit pid=2008)\u001b[0m [1000]\tvalid_set's l1: 0.109615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2113)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2113)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=2113)\u001b[0m [1000]\tvalid_set's l1: 0.114494\n",
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m [1000]\tvalid_set's l1: 0.102821\n",
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m [2000]\tvalid_set's l1: 0.100869\n",
            "\u001b[36m(_ray_fit pid=2075)\u001b[0m [3000]\tvalid_set's l1: 0.100844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.1082\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t42.47s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t1.6s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 108.37s of the 188.63s of remaining time.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\u001b[36m(_ray_fit pid=2113)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=2113)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=2113)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=2113)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=2113)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=2199)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=2199)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=2199)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2199)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=2199)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=2199)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2199)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=2200)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2200)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=2199)\u001b[0m [1000]\tvalid_set's l1: 0.0967386\n",
            "\u001b[36m(_ray_fit pid=2200)\u001b[0m [1000]\tvalid_set's l1: 0.115821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=2313)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2313)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2313)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2313)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2313)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2313)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2313)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2314)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2314)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=2313)\u001b[0m [1000]\tvalid_set's l1: 0.118191\n",
            "\u001b[36m(_ray_fit pid=2314)\u001b[0m [1000]\tvalid_set's l1: 0.107227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=2411)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2411)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2411)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2411)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2411)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2411)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2411)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2412)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2412)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=2411)\u001b[0m [1000]\tvalid_set's l1: 0.116881\n",
            "\u001b[36m(_ray_fit pid=2412)\u001b[0m [1000]\tvalid_set's l1: 0.111847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=2520)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2520)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2520)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2520)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2520)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2520)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2520)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=2520)\u001b[0m [1000]\tvalid_set's l1: 0.102158\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=2568)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=2568)\u001b[0m \n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.1098\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t40.59s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.83s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 63.99s of the 144.26s of remaining time.\n",
            "\u001b[36m(_ray_fit pid=2568)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=2568)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=2568)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=2568)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=2568)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.1234\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t7.86s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.56s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 55.03s of the 135.30s of remaining time.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\u001b[36m(_ray_fit pid=2684)\u001b[0m \tRan out of time, early stopping on iteration 1227.\n",
            "\u001b[36m(_ray_fit pid=2814)\u001b[0m \tRan out of time, early stopping on iteration 1177.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=2948)\u001b[0m \tRan out of time, early stopping on iteration 1179.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3082)\u001b[0m \tRan out of time, early stopping on iteration 1165.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.1134\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t58.09s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.07s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 240.72s of the 73.01s of remaining time.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.364, 'LightGBM_BAG_L1': 0.364, 'RandomForestMSE_BAG_L1': 0.136, 'CatBoost_BAG_L1': 0.136}\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.103\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.11s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 72.89s of the 72.85s of remaining time.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\u001b[36m(_ray_fit pid=3215)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=3215)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=3215)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3215)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=3215)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=3215)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3215)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=3085)\u001b[0m \tRan out of time, early stopping on iteration 1168.\n",
            "\u001b[36m(_ray_fit pid=3216)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3216)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3307)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3307)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3307)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3307)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3307)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3307)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3307)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3312)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3312)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(autoscaler +3m17s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[33m(autoscaler +3m17s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=3411)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3411)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3411)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3411)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3411)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3411)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3411)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3414)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3414)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3506)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3506)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3506)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3506)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3506)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3506)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3506)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3547)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3547)\u001b[0m \n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.1013\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t31.31s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.27s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 37.77s of the 37.73s of remaining time.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\u001b[36m(_ray_fit pid=3617)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3617)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3617)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3617)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3617)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3617)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3617)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3616)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3616)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3722)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3722)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3722)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3722)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3722)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3722)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3722)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3723)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3723)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m(autoscaler +3m52s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=3816)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3816)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3816)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3816)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3816)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3816)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3816)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3821)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3821)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3920)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3920)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3920)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3920)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3920)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3920)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3920)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=3923)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=3923)\u001b[0m \n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.0992\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t37.34s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.07s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 240.72s of the -3.92s of remaining time.\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.6, 'LightGBMXT_BAG_L2': 0.333, 'CatBoost_BAG_L1': 0.067}\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t-0.0975\t = Validation score   (-mean_absolute_error)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.08s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m AutoGluon training complete, total runtime = 244.83s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 195.4 rows/s (572 batch size)\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250213_174122/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m \n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m /usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=1578)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                    model  score_holdout  score_val          eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0     WeightedEnsemble_L3      -0.098842  -0.097479  mean_absolute_error        5.063636       3.486142  217.763401                 0.002763                0.001114           0.081721            3       True         10\n",
            "1         LightGBM_BAG_L2      -0.099561  -0.099204  mean_absolute_error        4.828724       3.218026  186.376040                 0.065592                0.069195          37.342622            2       True          9\n",
            "2       LightGBMXT_BAG_L2      -0.102694  -0.101286  mean_absolute_error        4.995282       3.415833  180.339057                 0.232150                0.267002          31.305640            2       True          8\n",
            "3     WeightedEnsemble_L2      -0.106191  -0.103040  mean_absolute_error        4.627397       3.075310  149.123109                 0.003498                0.001094           0.108313            2       True          7\n",
            "4       LightGBMXT_BAG_L1      -0.110044  -0.108193  mean_absolute_error        2.734552       1.604603   42.467696                 2.734552                1.604603          42.467696            1       True          3\n",
            "5         LightGBM_BAG_L1      -0.110512  -0.109750  mean_absolute_error        0.972455       0.832402   40.593035                 0.972455                0.832402          40.593035            1       True          4\n",
            "6         CatBoost_BAG_L1      -0.117664  -0.113373  mean_absolute_error        0.611114       0.074572   58.091993                 0.611114                0.074572          58.091993            1       True          6\n",
            "7  RandomForestMSE_BAG_L1      -0.129770  -0.123388  mean_absolute_error        0.305778       0.562638    7.862072                 0.305778                0.562638           7.862072            1       True          5\n",
            "8   KNeighborsUnif_BAG_L1      -0.823666  -0.817204  mean_absolute_error        0.075040       0.037597    0.009046                 0.075040                0.037597           0.009046            1       True          1\n",
            "9   KNeighborsDist_BAG_L1      -0.922272  -0.894307  mean_absolute_error        0.064194       0.037018    0.009576                 0.064194                0.037018           0.009576            1       True          2\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t262s\t = DyStack   runtime |\t738s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 738s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250213_174122\"\n",
            "Train Data Rows:    5148\n",
            "Train Data Columns: 15\n",
            "Label Column:       Weekly_Sales\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10422.14 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.59 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) :  4 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
            "\t\t('int', [])   : 11 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     :  4 | ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
            "\t\t('int', [])       :  1 | ['Month']\n",
            "\t\t('int', ['bool']) : 10 | ['Store_0', 'Store_1', 'Store_2', 'Store_3', 'Store_4', ...]\n",
            "\t0.3s = Fit runtime\n",
            "\t15 features in original data used to generate 15 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.25 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.33s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 491.55s of the 737.46s of remaining time.\n",
            "\t-0.8181\t = Validation score   (-mean_absolute_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 488.43s of the 734.33s of remaining time.\n",
            "\t-0.9035\t = Validation score   (-mean_absolute_error)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 488.34s of the 734.24s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\t-0.1061\t = Validation score   (-mean_absolute_error)\n",
            "\t50.48s\t = Training   runtime\n",
            "\t2.41s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 429.95s of the 675.85s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
            "\t-0.1068\t = Validation score   (-mean_absolute_error)\n",
            "\t40.5s\t = Training   runtime\n",
            "\t1.45s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 383.99s of the 629.90s of remaining time.\n",
            "\t-0.1211\t = Validation score   (-mean_absolute_error)\n",
            "\t10.49s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 372.71s of the 618.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\t-0.1033\t = Validation score   (-mean_absolute_error)\n",
            "\t314.63s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 54.00s of the 299.91s of remaining time.\n",
            "\t-0.1163\t = Validation score   (-mean_absolute_error)\n",
            "\t4.03s\t = Training   runtime\n",
            "\t0.59s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 48.73s of the 294.64s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
            "\t-0.1298\t = Validation score   (-mean_absolute_error)\n",
            "\t84.62s\t = Training   runtime\n",
            "\t0.49s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 206.07s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.4, 'LightGBM_BAG_L1': 0.25, 'ExtraTreesMSE_BAG_L1': 0.15, 'LightGBMXT_BAG_L1': 0.1, 'NeuralNetFastAI_BAG_L1': 0.1}\n",
            "\t-0.0983\t = Validation score   (-mean_absolute_error)\n",
            "\t0.18s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 205.87s of the 205.81s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\t-0.0963\t = Validation score   (-mean_absolute_error)\n",
            "\t37.87s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 162.50s of the 162.45s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\t-0.0924\t = Validation score   (-mean_absolute_error)\n",
            "\t31.65s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 126.50s of the 126.45s of remaining time.\n",
            "\t-0.0912\t = Validation score   (-mean_absolute_error)\n",
            "\t29.89s\t = Training   runtime\n",
            "\t0.39s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 95.52s of the 95.47s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "\t-0.0912\t = Validation score   (-mean_absolute_error)\n",
            "\t73.95s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 17.72s of the 17.66s of remaining time.\n",
            "\t-0.0891\t = Validation score   (-mean_absolute_error)\n",
            "\t9.34s\t = Training   runtime\n",
            "\t0.5s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 7.48s of the 7.43s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
            "\t-0.1663\t = Validation score   (-mean_absolute_error)\n",
            "\t50.41s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -47.05s of remaining time.\n",
            "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L2': 0.625, 'CatBoost_BAG_L2': 0.25, 'CatBoost_BAG_L1': 0.042, 'LightGBM_BAG_L2': 0.042, 'RandomForestMSE_BAG_L2': 0.042}\n",
            "\t-0.0884\t = Validation score   (-mean_absolute_error)\n",
            "\t0.22s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 785.17s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 130.5 rows/s (644 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250213_174122\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f6592bfc710>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance\n",
        "performance = predictor.evaluate(test_data)\n",
        "print(\"Model Performance:\", performance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Wm0XtELZt6z",
        "outputId": "bb4cac3c-f9d6-49b7-a72b-6bedda5f1817"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance: {'mean_absolute_error': -0.09118302798777257, 'root_mean_squared_error': -0.16379375983750477, 'mean_squared_error': -0.026828395761706193, 'r2': 0.9734792646570037, 'pearsonr': 0.986670215526246, 'median_absolute_error': -0.05143883120517789}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show feature importance\n",
        "importance = predictor.feature_importance(test_data)\n",
        "print(importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE8wfCggZt8K",
        "outputId": "40ad54ab-d4cf-461f-a113-f4a28d1d41b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing feature importance via permutation shuffling for 15 features using 1287 rows with 5 shuffle sets...\n",
            "\t45.31s\t= Expected runtime (9.06s per shuffle set)\n",
            "\t34.7s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              importance    stddev       p_value  n  p99_high   p99_low\n",
            "Store_0         0.444420  0.013153  9.194914e-08  5  0.471501  0.417338\n",
            "Store_5         0.382740  0.018516  6.552929e-07  5  0.420865  0.344615\n",
            "CPI             0.361133  0.017161  6.101096e-07  5  0.396468  0.325797\n",
            "Store_4         0.346226  0.006634  1.617159e-08  5  0.359886  0.332566\n",
            "Store_1         0.318522  0.008883  7.251662e-08  5  0.336812  0.300231\n",
            "Unemployment    0.196016  0.011803  1.569711e-06  5  0.220317  0.171714\n",
            "Store_3         0.147406  0.008366  1.239800e-06  5  0.164632  0.130180\n",
            "Store_2         0.116194  0.004533  2.772800e-07  5  0.125527  0.106862\n",
            "Month           0.051547  0.002872  1.151024e-06  5  0.057460  0.045634\n",
            "Holiday_Flag    0.022575  0.001503  2.346160e-06  5  0.025670  0.019479\n",
            "Fuel_Price      0.018788  0.002588  4.212367e-05  5  0.024117  0.013460\n",
            "Temperature     0.016073  0.001336  5.674696e-06  5  0.018824  0.013322\n",
            "Season_2        0.007884  0.000660  5.828138e-06  5  0.009243  0.006526\n",
            "Season_1        0.001383  0.000450  1.173143e-03  5  0.002310  0.000457\n",
            "Season_0        0.000795  0.000116  5.383715e-05  5  0.001034  0.000555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Weekly_Sales for the test set\n",
        "predictions = predictor.predict(X_test)\n",
        "print(predictions.head())  # Show first few predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCFt2-o6ZuBa",
        "outputId": "5ce65bc1-7e23-40fb-b203-35f1da2a53d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2436    0.151078\n",
            "3361    0.619520\n",
            "233     1.304853\n",
            "3667   -0.150445\n",
            "5011   -1.034155\n",
            "Name: Weekly_Sales, dtype: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gFji8_-JZuNL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}